import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import tensorflow as tf
from transformers import AutoTokenizer
from tensorflow.keras import layers, Model
from tensorflow.keras.models import model_from_json
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="Kurlypool ì±—ë´‡", layout="centered")
st.title("ğŸ³ Kurlypool ì±—ë´‡")
st.markdown("ë¦¬ë·° ê¸°ë°˜ ê°„í¸ì‹ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

MAX_LEN = 80
CATEGORICAL_DIM = 64

# --- ì»¤ìŠ¤í…€ BERT ë˜í¼ ---
class TFBertModelWrapper(layers.Layer):
    def __init__(self, pretrained_model, **kwargs):
        super().__init__(**kwargs)
        self.bert = pretrained_model

    def call(self, inputs):
        input_ids, attention_mask = inputs
        outputs = self.bert({'input_ids': input_ids, 'attention_mask': attention_mask})
        return outputs.last_hidden_state

# --- ê²½ë¡œ ì„¤ì • ---
BASE_PATH = os.path.dirname(os.path.abspath(__file__))
TOKENIZER_NAME = "beomi/kcbert-base"
SBERT_MODEL_NAME = "jhgan/ko-sroberta-multitask"
ANSWER_CSV_PATH = os.path.join(BASE_PATH, "..", "ì±—ë´‡íŠ¹ì§•ì¶”ì¶œìµœì¢….csv")

# --- ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
def clean_text(text):
    text = re.sub(r'([a-zA-Z0-9])[^a-zA-Z0-9ê°€-í£\s]+([a-zA-Z0-9])', r'\1 \2', str(text))
    text = re.sub(r'[^a-zA-Z0-9ê°€-í£\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# --- ëª¨ë¸, í† í¬ë‚˜ì´ì €, SBERT ë¡œë“œ ---
@st.cache_resource
def load_model_and_tokenizer():
    # JSON ê²½ë¡œ
    model_json_path = os.path.join(BASE_PATH, "bert_model", "intent_model.json")
    weight_path = os.path.join(BASE_PATH, "bert_model", "intent_model.weights.h5")
    
    # ëª¨ë¸ êµ¬ì¡° ë¡œë“œ
    with open(model_json_path, "r", encoding="utf-8") as json_file:
        loaded_model_json = json_file.read()

    # ëª¨ë¸ ë³µì›
    pretrained_bert = TFAutoModel.from_pretrained(TOKENIZER_NAME)
    model = tf.keras.models.model_from_json(
        loaded_model_json,
        custom_objects={"TFBertModelWrapper": TFBertModelWrapper}
    )
    model.load_weights(weight_path)

    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)

    return model, tokenizer

@st.cache_resource
def load_sbert():
    return SentenceTransformer(SBERT_MODEL_NAME)

@st.cache_data
def load_answer_df():
    encodings = ["utf-8", "cp949", "euc-kr", "utf-8-sig"]
    for enc in encodings:
        try:
            df = pd.read_csv(ANSWER_CSV_PATH, encoding=enc)
            if "ë‹µë³€" in df.columns:
                df.columns = df.columns.str.strip().str.lower()
                return df
        except:
            continue
    return pd.DataFrame()

@st.cache_data
def compute_embeddings(df, sbert_model):
    texts = df["ë‹µë³€"].astype(str).tolist()
    embeddings = sbert_model.encode(texts, convert_to_tensor=False, show_progress_bar=False)
    return texts, embeddings

# --- ì˜ë„ ì˜ˆì¸¡ ---
def predict_intent(text, model, tokenizer):
    clean = clean_text(text)
    tokens = tokenizer([clean], padding="max_length", truncation=True, max_length=MAX_LEN, return_tensors="tf")
    dummy_cat = np.zeros((1, CATEGORICAL_DIM))
    pred = model.predict([tokens["input_ids"], tokens["attention_mask"], dummy_cat], verbose=0)
    return "RECOMMEND" if np.argmax(pred) == 0 else "TREND"

# --- ìœ ì‚¬í•œ ë‹µë³€ ì¶”ì¶œ ---
def get_best_answer(query, texts, embeddings, sbert_model):
    query_vec = sbert_model.encode([query], convert_to_tensor=False)
    sims = cosine_similarity(query_vec, embeddings)[0]
    best_idx = sims.argmax()
    return texts[best_idx]

# --- ì‹¤í–‰ ë¶€ë¶„ ---
user_input = st.text_input("â“ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:")

if st.button("ë‹µë³€ ë°›ê¸°") and user_input.strip():
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        model, tokenizer = load_model_and_tokenizer()
        sbert_model = load_sbert()
        answer_df = load_answer_df()
        texts, emb = compute_embeddings(answer_df, sbert_model)

        intent = predict_intent(user_input, model, tokenizer)
        answer = get_best_answer(user_input, texts, emb, sbert_model)

        st.markdown(f"**ì˜ˆì¸¡ëœ ì˜ë„:** `{intent}`")
        st.markdown(f"**ì±—ë´‡ ì‘ë‹µ:** {answer}")
