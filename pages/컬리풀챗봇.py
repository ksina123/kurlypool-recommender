import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import tensorflow as tf
import time
from transformers import AutoTokenizer, TFAutoModel
from tensorflow.keras.models import load_model
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# --- ì»¤ìŠ¤í…€ BERT ë ˆì´ì–´ ì •ì˜ ---
from tensorflow.keras import layers
class TFBertModelWrapper(layers.Layer):
    def __init__(self, model_name="beomi/kcbert-base", **kwargs):
        super().__init__(**kwargs)
        self.bert = TFAutoModel.from_pretrained(model_name)
    def call(self, inputs):
        input_ids, attention_mask = inputs
        outputs = self.bert({'input_ids': input_ids, 'attention_mask': attention_mask})
        return outputs.last_hidden_state

# --- ì„¤ì • ---
MODEL_PATH = '0715_intent_model_final.h5'
TOKENIZER_NAME = 'beomi/kcbert-base'
SBERT_MODEL = 'jhgan/ko-sroberta-multitask'
CSV_FILES = {
    "TREND": "ì±—ë´‡íŠ¹ì§•ì¶”ì¶œìµœì¢….csv"
}

@st.cache_resource
def load_intent_model():
    return load_model(MODEL_PATH, custom_objects={'TFBertModelWrapper': TFBertModelWrapper})

@st.cache_resource
def load_tokenizer():
    return AutoTokenizer.from_pretrained(TOKENIZER_NAME)

@st.cache_resource
def load_sbert():
    return SentenceTransformer(SBERT_MODEL)

@st.cache_data
def load_answer_dfs():
    dfs = {}
    for key, path in CSV_FILES.items():
        if os.path.exists(path):
            encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']
            df = None
            for enc in encodings:
                try:
                    df = pd.read_csv(path, encoding=enc)
                    break
                except:
                    continue
            if df is not None:
                df.columns = df.columns.str.lower().str.strip()
                dfs[key] = df
    return dfs

# --- í…ìŠ¤íŠ¸ ì •ì œ ---
def clean_text(text):
    text = re.sub(r'([a-zA-Z0-9])[^a-zA-Z0-9ê°€-í£\s]+([a-zA-Z0-9])', r'\1 \2', str(text))
    text = re.sub(r'[^a-zA-Z0-9ê°€-í£\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# --- ì˜ë„ ì˜ˆì¸¡ ---
def predict_intent(user_input, model, tokenizer):
    try:
        text = clean_text(user_input)
        X_input = tokenizer([text], padding='max_length', truncation=True, max_length=80, return_tensors='tf')
        dummy_cat = np.zeros((1, 64))
        pred = model.predict([X_input['input_ids'], X_input['attention_mask'], dummy_cat], verbose=0)
        idx2label = {0: "RECOMMEND", 1: "TREND", 2: "NEGFAQ"}
        intent_idx = np.argmax(pred, axis=1)[0]
        return idx2label.get(intent_idx, "TREND")
    except Exception:
        return "TREND"

# --- intentë³„ ë°ì´í„° ì„ íƒ ---
def select_df_by_intent(intent, dfs):
    return dfs.get("TREND")

# --- ì‚¬ì „ ì„ë² ë”© ê³„ì‚° ---
@st.cache_data
def precompute_all_embeddings(dfs, sbert_model):
    emb_dict = {}
    for key, df in dfs.items():
        if 'ë‹µë³€' in df.columns and len(df):
            texts = df['ë‹µë³€'].astype(str).tolist()
            emb = sbert_model.encode(texts, convert_to_tensor=False, show_progress_bar=False)
            emb_dict[key] = {"emb": emb, "texts": texts}
    return emb_dict

# --- ë² ìŠ¤íŠ¸ ë‹µë³€ ìœ ì‚¬ë„ ê³„ì‚° ---
def get_best_answer(user_input, answer_df, emb_dict, sbert_model):
    if answer_df is None or len(answer_df) == 0:
        return "ë‹µë³€ í›„ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    key = None
    for k, v in emb_dict.items():
        if answer_df is not None and 'texts' in v and len(v['texts']) == len(answer_df):
            key = k
            break
    if key is None:
        return "ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    texts = emb_dict[key]['texts']
    q_embeddings = emb_dict[key]['emb']
    user_emb = sbert_model.encode([user_input], convert_to_tensor=False)
    sims = cosine_similarity(user_emb, q_embeddings)[0]
    best_idx = sims.argmax()
    return texts[best_idx]

# --- ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ---
def process_user_input(user_input, intent_model, tokenizer, dfs, emb_dict, sbert_model):
    intent = predict_intent(user_input, intent_model, tokenizer)
    df = select_df_by_intent(intent, dfs)
    answer = get_best_answer(user_input, df, emb_dict, sbert_model)
    return answer, intent

# --- UI í…ŒìŠ¤íŠ¸ìš© (ì˜ˆì‹œ) ---
if __name__ == "__main__":
    st.set_page_config(page_title="Kurlypool ì±—ë´‡", layout="centered")
    st.title("ğŸ’¬ Kurlypool ì±—ë´‡")

    model = load_intent_model()
    tokenizer = load_tokenizer()
    sbert_model = load_sbert()
    dfs = load_answer_dfs()
    emb_dict = precompute_all_embeddings(dfs, sbert_model)

    user_input = st.text_input("ê²€ìƒ‰", placeholder="ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", key="main_search", label_visibility="collapsed")

    if st.button("ê²€ìƒ‰"):
        if user_input:
            answer, intent = process_user_input(user_input, model, tokenizer, dfs, emb_dict, sbert_model)
            st.markdown(f"**ì˜ë„:** `{intent}`")
            st.markdown(f"**ë‹µë³€:** {answer}")
